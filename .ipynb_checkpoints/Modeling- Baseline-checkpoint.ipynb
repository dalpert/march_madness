{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Modeling\n",
    "#### Robert Shaw\n",
    "#### CS109a Project: Data Driven March Madness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Our Datasets and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import march_madness_classes as mmc\n",
    "\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teams = pd.read_csv(\"datasets/kaggle_data/Teams.csv\")\n",
    "seeds = pd.read_csv(\"datasets/kaggle_data/TourneySeeds.csv\")\n",
    "slots = pd.read_csv(\"datasets/kaggle_data/TourneySlots.csv\")\n",
    "tourney_data = pd.read_csv(\"datasets/kaggle_data/TourneyCompactResults.csv\")\n",
    "regular_data = pd.read_csv(\"datasets/kaggle_data/RegularSeasonCompactResults.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tourney_arr = mmc.filter_into_seasons(tourney_data)\n",
    "regular_arr = mmc.filter_into_seasons(regular_data)\n",
    "seeds_arr = mmc.filter_into_seasons(seeds)\n",
    "slots_arr = mmc.filter_into_seasons(slots)\n",
    "\n",
    "seeds_1985 = seeds_arr[0]\n",
    "slots_1985 = slots_arr[0]\n",
    "tourney_1985 = tourney_arr[0]\n",
    "regular_1985 = regular_arr[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the Stationary Distibution Data Into One DataFrame/CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stationary_arr = []\n",
    "for i in range(1985, 2017):\n",
    "    df = pd.read_csv(\"datasets/our_data/markov_data/{}_stationary_distribution\".format(i), index_col = 0)\n",
    "    df.columns = [i]\n",
    "    stationary_arr.append(df.transpose()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concat into a \n",
    "stationary_df = pd.concat(stationary_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save as a csv\n",
    "stationary_df.to_csv(\"datasets/our_data/stationary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1985    1.0\n",
       "1986    1.0\n",
       "1987    1.0\n",
       "1988    1.0\n",
       "1989    1.0\n",
       "1990    1.0\n",
       "1991    1.0\n",
       "1992    1.0\n",
       "1993    1.0\n",
       "1994    1.0\n",
       "1995    1.0\n",
       "1996    1.0\n",
       "1997    1.0\n",
       "1998    1.0\n",
       "1999    1.0\n",
       "2000    1.0\n",
       "2001    1.0\n",
       "2002    1.0\n",
       "2003    1.0\n",
       "2004    1.0\n",
       "2005    1.0\n",
       "2006    1.0\n",
       "2007    1.0\n",
       "2008    1.0\n",
       "2009    1.0\n",
       "2010    1.0\n",
       "2011    1.0\n",
       "2012    1.0\n",
       "2013    1.0\n",
       "2014    1.0\n",
       "2015    1.0\n",
       "2016    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# everything appears to be working if they sum to one\n",
    "stationary_df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Predictors For Our Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stationary = pd.read_csv(\"datasets/our_data/stationary\", index_col =0)\n",
    "avg_points_against =  pd.read_csv(\"datasets/our_data/avg_points_against\", index_col =0)\n",
    "avg_points_for = pd.read_csv(\"datasets/our_data/avg_points_for\", index_col =0)\n",
    "away_wins = pd.read_csv(\"datasets/our_data/away_wins\", index_col =0)\n",
    "bad_losses = pd.read_csv(\"datasets/our_data/bad_losses\", index_col =0)\n",
    "consistency= pd.read_csv(\"datasets/our_data/consistency\", index_col =0)\n",
    "dominance= pd.read_csv(\"datasets/our_data/dominance\", index_col =0)\n",
    "good_wins_matrix= pd.read_csv(\"datasets/our_data/good_wins_matrix\", index_col =0)\n",
    "rpi= pd.read_csv(\"datasets/our_data/rpi\", index_col =0)\n",
    "tough_wins= pd.read_csv(\"datasets/our_data/tough_wins\", index_col =0)\n",
    "win_percentage= pd.read_csv(\"datasets/our_data/win_percentage\", index_col =0)\n",
    "win_percentage_vs_tourney_teams_matrix= pd.read_csv(\"datasets/our_data/win_percentage_vs_tourney_teams_matrix\", index_col =0)\n",
    "wins_vs_tourney_teams= pd.read_csv(\"datasets/our_data/wins_vs_tourney_teams\", index_col =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to go into our March Madness Classes Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extracting from the dataframe\n",
    "def get_predictor(team_id, year, df):\n",
    "    return df.loc[year, str(team_id)]\n",
    "\n",
    "def get_predictor_dif(team_id_1, team_id_2, year, df):\n",
    "    return df.loc[year, str(team_id_1)] - df.loc[year, str(team_id_2)]\n",
    "\n",
    "def get_predictors(team_id, year, df_arr):\n",
    "    row = np.zeros(len(df_arr))\n",
    "    i = 0\n",
    "    for df in df_arr:\n",
    "        row[i] = get_predictor(team_id, year, df)\n",
    "        i = i + 1\n",
    "    return row\n",
    "\n",
    "def get_predictors_dif(team_id_1, team_id_2, year, df_arr):\n",
    "    row = np.zeros(len(df_arr))\n",
    "    i = 0\n",
    "    for df in df_arr:\n",
    "        row[i] = float(get_predictor_dif(team_id_1, team_id_2, year, df))\n",
    "        i = i + 1\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to extract the y_values of the team with the min index winning\n",
    "def extract_response(tourney_game_df):\n",
    "    \n",
    "    # response for a given year\n",
    "    min_index_win = np.zeros(tourney_game_df.shape[0])\n",
    "    i = 0\n",
    "    for index, game in tourney_game_df.iterrows():\n",
    "        if int(game[\"Prediction\"]) == min(int(game[\"Strongseed Team\"]), int(game[\"Weakseed Team\"])):\n",
    "            min_index_win[i] = 1 \n",
    "        i = i + 1\n",
    "        \n",
    "    \n",
    "    return min_index_win\n",
    "\n",
    "# function to extract the y_values of the team with the min index winning\n",
    "def extract_predictors(tourney_game_df, predictor_list, predictor_dfs, year):\n",
    "    # buffer to hold our values\n",
    "    pred_matrix = np.zeros((tourney_game_df.shape[0], len(predictor_list)))\n",
    "    \n",
    "    # fill predictor matrix\n",
    "    for i in range(tourney_game_df.shape[0]):   \n",
    "        # min and max index teams\n",
    "        min_index_team = min(int(tourney_game_df.loc[i, \"Strongseed Team\"]), int(tourney_game_df.loc[i, \"Weakseed Team\"]))\n",
    "        max_index_team = max(int(tourney_game_df.loc[i, \"Strongseed Team\"]), int(tourney_game_df.loc[i, \"Weakseed Team\"]))                  \n",
    "\n",
    "        # fill matrix\n",
    "        pred_matrix[i,  0] = min_index_team\n",
    "        pred_matrix[i,  1] = max_index_team\n",
    "        pred_matrix[i, 2:] = get_predictors_dif(min_index_team, max_index_team, year, predictor_dfs)\n",
    "\n",
    "    # gen dataframe                       \n",
    "    pred_df = pd.DataFrame(data = pred_matrix, columns = predictor_list)\n",
    "                           \n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tourney_results(seeds, slots, raw_data):\n",
    "    tourney = mmc.Tournament(seeds, slots, mmc.ActualTournament(raw_data))\n",
    "    tourney.simulate_tournament()\n",
    "    return tourney.entire_bracket\n",
    "\n",
    "# get single years worth of games\n",
    "def generate_single_year_of_games(year, seed_list, slot_list, tourney_data, predictors, predictor_dfs):\n",
    "    # get results of the games\n",
    "    tourney_results = get_tourney_results(seed_list, slot_list, tourney_data)\n",
    "    \n",
    "    # get predictors\n",
    "    pred_df = extract_predictors(tourney_results, predictors, predictor_dfs, year)\n",
    "    \n",
    "    # get response\n",
    "    resp_arr = extract_response(tourney_results)\n",
    "    \n",
    "    return pred_df, resp_arr\n",
    "\n",
    "def generate_multiple_years_of_games(years, seed_list_arr, slot_list_arr, tourney_data_arr, predictors, predictor_dfs):\n",
    "    min_year = 1985\n",
    "\n",
    "    preds = pd.DataFrame({})\n",
    "    resps = np.array([])\n",
    "    \n",
    "    for year in years:\n",
    "        year_index = int(year) - min_year\n",
    "        # generate 1 year of data\n",
    "        pred_df, resp_arr = generate_single_year_of_games(year, \n",
    "                                                          seed_list_arr[year_index], \n",
    "                                                          slot_list_arr[year_index], \n",
    "                                                          tourney_data_arr[year_index],\n",
    "                                                          predictors,\n",
    "                                                          predictor_dfs)\n",
    "        print year\n",
    "        # add to list we are keeping \n",
    "        preds = pd.concat([preds, pred_df])\n",
    "        resps = np.concatenate((resps, resp_arr))\n",
    "        \n",
    "    return preds, resps\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column_names = [\"min_index_id\", \"max_index_id\",\n",
    "\"bad_losses dif\",\n",
    "\"consistency dif\",\n",
    "\"dominance dif\",\n",
    "\"rpi dif\",\n",
    "\"stationary dif\",\n",
    "\"wins_vs_tourney_teams dif\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tourney_arr = mmc.filter_into_seasons(tourney_data)\n",
    "regular_arr = mmc.filter_into_seasons(regular_data)\n",
    "seeds_arr = mmc.filter_into_seasons(seeds)\n",
    "slots_arr = mmc.filter_into_seasons(slots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictor_dfs = [bad_losses, consistency, dominance, rpi, stationary, wins_vs_tourney_teams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "pred, resp = generate_multiple_years_of_games(range(1985, 2001), seeds_arr, slots_arr, tourney_arr, column_names, predictor_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_df = pred.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resp_df = pd.DataFrame(data=resp, columns=[\"min_index_win\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=1008, step=1)\n",
      "RangeIndex(start=0, stop=1008, step=1)\n"
     ]
    }
   ],
   "source": [
    "print pred_df.index\n",
    "print resp_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_index, cross_index = train_test_split(pred_df.index, test_size = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = pred_df.loc[train_index]\n",
    "train_y = resp_df.loc[train_index]\n",
    "cross_x = pred_df.loc[cross_index]\n",
    "cross_y = resp_df.loc[cross_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_model = LogReg(C=100)\n",
    "lda_model = LDA()\n",
    "qda_model = QDA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74206349206349209"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = logistic_model\n",
    "model.fit(train_x.iloc[:, 2:], train_y.values.T[0])\n",
    "model.score(cross_x.iloc[:, 2:], cross_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76190476190476186"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lda_model\n",
    "model.fit(train_x.iloc[:, 2:], train_y.values.T[0])\n",
    "model.score(cross_x.iloc[:, 2:], cross_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Into a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelPredictor(object):\n",
    "    # init function\n",
    "    def __init__(self, model, dfs_arr, year):\n",
    "        self.model = model\n",
    "        self.dfs_arr = dfs_arr\n",
    "        self.year = year\n",
    "        return\n",
    "    \n",
    "    # head to head predicitons\n",
    "    def predict(self, team_1, team_2):\n",
    "        team_1 = int(team_1)\n",
    "        team_2 = int(team_2)\n",
    "        \n",
    "        # min and max index\n",
    "        min_index_team = min(team_1, team_2)\n",
    "        max_index_team = max(team_1, team_2)\n",
    "        \n",
    "        # get the x values\n",
    "        row = get_predictors_dif(min_index_team, max_index_team, self.year, self.dfs_arr)\n",
    "\n",
    "        # predict under model\n",
    "        y_hat = model.predict(row.reshape(1,-1))\n",
    "        \n",
    "        if y_hat == 1:\n",
    "            return min_index_team\n",
    "        else:\n",
    "            return max_index_team\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "year = 1997\n",
    "\n",
    "seeds = seeds_arr[year - 1985]\n",
    "slots = slots_arr[year - 1985]\n",
    "resul = tourney_arr[year - 1985]\n",
    "\n",
    "tourney_actual = mmc.Tournament(seeds, slots, mmc.ActualTournament(resul))\n",
    "tourney_actual.simulate_tournament()\n",
    "\n",
    "tourney_top_seed = mmc.Tournament(seeds, slots, mmc.BasicPredictor())\n",
    "tourney_top_seed.simulate_tournament()\n",
    "\n",
    "tourney_model = mmc.Tournament(seeds, slots, ModelPredictor(logistic_model, predictor_dfs, year))\n",
    "tourney_model.simulate_tournament()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Points  : 960\n",
      "\n",
      "Total Accuracy: 41 / 63 = 0.650793650794\n",
      "R1    Accuracy: 24 / 32 = 0.75\n",
      "R2    Accuracy: 10 / 16 = 0.625\n",
      "R3    Accuracy: 3 / 8 = 0.375\n",
      "R4    Accuracy: 3 / 4 = 0.75\n",
      "R5    Accuracy: 1 / 2 = 0.5\n",
      "R6    Accuracy: 0 / 1 = 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(960, 0.6507936507936508)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tourney_model.score_model(tourney_actual, print_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Points  : 870\n",
      "\n",
      "Total Accuracy: 42 / 63 = 0.666666666667\n",
      "R1    Accuracy: 25 / 32 = 0.78125\n",
      "R2    Accuracy: 9 / 16 = 0.5625\n",
      "R3    Accuracy: 5 / 8 = 0.625\n",
      "R4    Accuracy: 3 / 4 = 0.75\n",
      "R5    Accuracy: 0 / 2 = 0.0\n",
      "R6    Accuracy: 0 / 1 = 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(870, 0.6666666666666666)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tourney_top_seed.score_model(tourney_actual, print_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_mod = np.zeros(len(range(1985, 2001)))\n",
    "accur_mod = np.zeros(len(range(1985, 2001)))\n",
    "\n",
    "score_top = np.zeros(len(range(1985, 2001)))\n",
    "accur_top = np.zeros(len(range(1985, 2001)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for year in range(1985, 2001):\n",
    "    seeds = seeds_arr[year - 1985]\n",
    "    slots = slots_arr[year - 1985]\n",
    "    resul = tourney_arr[year - 1985]\n",
    "\n",
    "    tourney_actual = mmc.Tournament(seeds, slots, mmc.ActualTournament(resul))\n",
    "    tourney_actual.simulate_tournament()\n",
    "\n",
    "    tourney_top_seed = mmc.Tournament(seeds, slots, mmc.BasicPredictor())\n",
    "    tourney_top_seed.simulate_tournament()\n",
    "\n",
    "    tourney_model = mmc.Tournament(seeds, slots, ModelPredictor(lda_model, predictor_dfs, year))\n",
    "    tourney_model.simulate_tournament()\n",
    "    \n",
    "    score_mod[i], accur_mod[i] = tourney_model.score_model(tourney_actual, print_res=False)\n",
    "    score_top[i], accur_top[i] = tourney_top_seed.score_model(tourney_actual, print_res=False)\n",
    "    \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "913.75\n",
      "0.64880952381\n"
     ]
    }
   ],
   "source": [
    "print np.mean(score_mod)\n",
    "print np.mean(accur_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "890.0\n",
      "0.64880952381\n"
     ]
    }
   ],
   "source": [
    "print np.mean(score_top)\n",
    "print np.mean(accur_top)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
